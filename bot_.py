# -*- coding: utf-8 -*-
"""bot .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/13oR-X6wm9rsPV-eVqmhc_EsnQVNtTYJT
"""

!pip install langchain
!pip install Huggingface_hub
!pip install langchain_community
!pip transformers
!pip install openai
!pip install chainlit
!pip install gradio

import os
import gradio as gr
import chainlit as cl
from langchain import HuggingFaceHub, LLMChain,   PromptTemplate

from getpass import getpass
HUGGINGFACEHUB_API_TOKEN = getpass()

import os
import chainlit as cl
from langchain import HuggingFaceHub, LLMChain,   PromptTemplate
import transformers
#model_id = transformers.AutoModelForCausalLM.from_pretrained(
 # 'mosaicml/mpt-7b-storywriter',
 # trust_remote_code=True
#)


from getpass import getpass
HUGGINGFACEHUB_API_TOKEN = getpass()


model_id = "Tincando/fiction_story_generator"
# Pass the API token using the correct lowercase keyword argument name
conv_model = HuggingFaceHub(huggingfacehub_api_token = HUGGINGFACEHUB_API_TOKEN,
                         repo_id = model_id,
                         model_kwargs={"temperature":0.8, "max_new_tokens":200})

from re import template
template = """
You are a helpful  AI assistant that makes the stories by completing the query given by the user.
{query}

"""

prompt = PromptTemplate(template=template, input_variables=["query"])




conv_chain = LLMChain(llm=conv_model,
                   prompt=prompt,
                   verbose=True)


print(conv_chain.run("The war for   .."))








# Function to generate story
def generate_story(query):
    response = conv_chain.run(query=query)
    return response

# Create the Gradio interface
iface = gr.Interface(
    fn=generate_story,
    inputs=gr.Textbox(lines=2, placeholder="Enter your story prompt..."),
    outputs=gr.Textbox(),
    title="AI Story Generator",
    description="Enter a story prompt to generate a unique story."
)

# Launch the Gradio interface
iface.launch()

from re import template
template = """
You are a helpful  AI assistant that makes the stories by completing the query given by the user.
{query}

"""

prompt = PromptTemplate(template=template, input_variables=["query"])

conv_chain = LLMChain(llm=conv_model,
                   prompt=prompt,
                   verbose=True)

print(conv_chain.run("The war for   .."))

